{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit Distance 2.0\n",
      "No of errors 2\n"
     ]
    }
   ],
   "source": [
    "def read_file(file):\n",
    "    '''\n",
    "    Purpose: Helper function: Read text files.\n",
    "    \n",
    "    Parameters: file: text file.\n",
    "                    \n",
    "    Returns: text: string format.\n",
    "    '''    \n",
    "    fp=codecs.open(file,\"r\",encoding='utf8',errors='ignore')\n",
    "    text=fp.readlines()\n",
    "    return text\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def edit_distance(seq1, seq2, s1, s2):\n",
    "    '''\n",
    "    Edit Distance Assumptions:\n",
    "    Cost of addition - 1\n",
    "    Cost of deletion - 1\n",
    "    Cost of substitution - 1\n",
    "    \n",
    "    Parameters:\n",
    "    seq1 - word sequence of input sentence\n",
    "    seq2 - word sequence of corrected sentence\n",
    "    s1 - input sentence string\n",
    "    s2 - correct sentence string\n",
    "    \n",
    "    Returns:\n",
    "    1. Edit Distance\n",
    "    2. List of errors ( each error in the form of a dictionary)\n",
    "    \n",
    "    '''\n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    bp = np.zeros((size_x,size_y,2))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "                if matrix[x,y] == matrix[x-1,y] + 1:\n",
    "                    bp[x,y,0] = x-1\n",
    "                    bp[x,y,1] = y\n",
    "                elif matrix[x,y] == matrix[x,y-1] + 1:\n",
    "                    bp[x,y,0] = x\n",
    "                    bp[x,y,1] = y-1\n",
    "                else:\n",
    "                    bp[x,y,0] = x-1\n",
    "                    bp[x,y,1] = y-1\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "                if matrix[x,y] == matrix[x-1,y] + 1:\n",
    "                    bp[x,y,0] = x-1\n",
    "                    bp[x,y,1] = y\n",
    "                elif matrix[x,y] == matrix[x,y-1] + 1:\n",
    "                    bp[x,y,0] = x\n",
    "                    bp[x,y,1] = y-1\n",
    "                else:\n",
    "                    bp[x,y,0] = x-1\n",
    "                    bp[x,y,1] = y-1\n",
    "                    \n",
    "    #print (matrix)\n",
    "    fx = int(size_x - 1)\n",
    "    fy = int(size_y - 1)\n",
    "    errors = []\n",
    "    while(fx != 0 or fy != 0):\n",
    "        nx = int(bp[fx,fy,0])\n",
    "        ny = int(bp[fx,fy,1])\n",
    "        \n",
    "        if (nx == fx - 1) and (ny == fy - 1):\n",
    "            \n",
    "            if seq1[nx] != seq2[ny]:\n",
    "                d = {}\n",
    "                d['error code'] = \"Grammar Error\"\n",
    "                d['description'] = \"Word statrting at index {offset} needs to be substituted\"\n",
    "                d['operation_required'] = \"Substitution\"\n",
    "                d['correction'] = [seq1[nx],seq2[ny]]\n",
    "                d['length'] = len(seq1[nx])\n",
    "                d['offset'] = s1.index(seq1[nx])\n",
    "                #print(d)\n",
    "                errors.append(d)\n",
    "                #print('\\n')\n",
    "                \n",
    "        elif (nx == fx) and (ny == fy - 1):\n",
    "            d = {}\n",
    "            d['error code'] = \"Grammar Error\"\n",
    "            d['description'] = \"Word need to be inserted in the first white space after {offset}\"\n",
    "            d['operation_required'] = \"Add\"\n",
    "            d['correction'] = seq2[ny]\n",
    "            if nx < len(seq1):\n",
    "                d['length'] = len(s1[s1.index(seq1[nx-1]):s1.index(seq1[nx])])+len(seq1[nx])\n",
    "            else:\n",
    "                d['length'] = len(s1[s1.index(seq1[nx-1]):])\n",
    "            d['offset'] = s1.index(seq1[nx-1])\n",
    "            #print(d)\n",
    "            errors.append(d)\n",
    "            #print('\\n')\n",
    "            \n",
    "        elif (nx == fx - 1) and (ny == fy):\n",
    "            d = {}\n",
    "            d['error code'] = \"Grammar Error\"\n",
    "            d['description'] = \"Word starting at index {offset} needs to be deleted\"\n",
    "            d['operation_required'] = \"Delete\"\n",
    "            d['correction'] = seq1[nx]\n",
    "            d['length'] = len(seq1[nx])\n",
    "            d['offset'] = s1.index(seq1[nx])\n",
    "            #print(d)\n",
    "            errors.append(d)\n",
    "            #print('\\n')\n",
    "            \n",
    "        fx = nx\n",
    "        fy = ny\n",
    "    return (matrix[size_x - 1, size_y - 1],errors)\n",
    "\n",
    "'''\n",
    "#For testing- \n",
    "s1 = \"this is great .\"\n",
    "s2 = \"This is great\"\n",
    "seq1 = word_tokenize(s1)\n",
    "seq2 = word_tokenize(s2)\n",
    "dist, errors = edit_distance(seq1,seq2,s1,s2)\n",
    "print(\"Edit Distance\", dist)\n",
    "print(\"No of errors\", len(errors))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grammar_correction(text):\n",
    "    '''\n",
    "    Purpose: \n",
    "    The function returns the output json format for the input sentence after obtaining \n",
    "    the correction for it from the model\n",
    "    \n",
    "    text - input sentence\n",
    "    t - corrected sentence obtained from model\n",
    "    '''\n",
    "    #t = model_output(text) \n",
    "    \n",
    "    seq1 = word_tokenize(text)\n",
    "    seq2 = word_tokenize(t)\n",
    "    dist, errors = edit_distance(seq1,seq2,text,t)\n",
    "\n",
    "    return_json={\n",
    "    \"text\":None,\n",
    "    \"errors\":[{\n",
    "        \"offset\":None,\n",
    "        \"length\":None,\n",
    "        \"error_code\":None,\n",
    "        \"error_category\":None,\n",
    "        \"description\":None,\n",
    "        \"correction\":None\n",
    "    },{\n",
    "        \"offset\":None,\n",
    "        \"length\":None,\n",
    "        \"error_code\":None,\n",
    "        \"error_category\":None,\n",
    "        \"description\":None,\n",
    "        \"correction\":None\n",
    "    }],\n",
    "    \"exceptions\":[],\n",
    "    \"correction\":None\n",
    "    }\n",
    "    return_json[\"errors\"]=errors\n",
    "    return_json[\"text\"]=text\n",
    "    return_json[\"correction\"]=t\n",
    "    \n",
    "    return return_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    test_file_path=\"test_data.txt\"\n",
    "    text=read_file(test_file_path)\n",
    "    for t in text:\n",
    "        print(grammar_correction(t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
